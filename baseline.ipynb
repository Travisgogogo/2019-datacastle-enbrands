{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import lightgbm as lgb\n",
    "from tqdm import tqdm, tqdm_notebook, tnrange\n",
    "from sklearn.preprocessing import LabelEncoder,OneHotEncoder\n",
    "from sklearn.model_selection import StratifiedKFold, train_test_split\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer, CountVectorizer\n",
    "from sklearn.decomposition import TruncatedSVD\n",
    "from sklearn.preprocessing import PolynomialFeatures\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.linear_model import LogisticRegression,HuberRegressor\n",
    "from sklearn.linear_model import SGDClassifier,PassiveAggressiveClassifier,RidgeClassifier\n",
    "from sklearn.naive_bayes import BernoulliNB,MultinomialNB\n",
    "from sklearn.svm import LinearSVC\n",
    "from scipy.sparse import hstack,vstack\n",
    "import datetime\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Loading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['order_detail_id', 'order_id', 'order_total_num', 'order_amount',\n",
       "       'order_total_payment', 'order_total_discount', 'order_pay_time',\n",
       "       'order_status', 'order_count', 'is_customer_rate',\n",
       "       'order_detail_status', 'order_detail_goods_num', 'order_detail_amount',\n",
       "       'order_detail_payment', 'order_detail_discount', 'customer_province',\n",
       "       'customer_city', 'member_id', 'customer_id', 'customer_gender',\n",
       "       'member_status', 'is_member_actived', 'goods_id', 'goods_price',\n",
       "       'goods_status', 'goods_has_discount', 'goods_list_time',\n",
       "       'goods_delist_time'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train = pd.read_csv('../data/round1_diac2019_train.csv', parse_dates=['order_pay_time','goods_list_time','goods_delist_time'])\n",
    "train.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_last shape: (539577, 28) train_label shape: (861254, 28) train_all shape: (1400831, 28)\n"
     ]
    }
   ],
   "source": [
    "train_last = train[((train['order_pay_time'].dt.date).astype(str)<='2013-07-03')]\n",
    "train_label = train[(train['order_pay_time'].dt.date).astype(str)>='2013-07-04']\n",
    "\n",
    "train_all = train[((train['order_pay_time'].dt.date).astype(str)<='2013-12-31')]\n",
    "print('train_last shape:',train_last.shape,'train_label shape:',train_label.shape,'train_all shape:',train_all.shape)\n",
    "\n",
    "last_data = pd.DataFrame(train_last[['customer_id']]).drop_duplicates(['customer_id']).dropna()\n",
    "all_data = pd.DataFrame(train_all[['customer_id']]).drop_duplicates(['customer_id']).dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_last['order_pay_month'] = train_last['order_pay_time'].dt.month\n",
    "train_last['order_pay_dayofweek'] = train_last['order_pay_time'].dt.dayofweek\n",
    "train_last['order_pay_day'] = train_last['order_pay_time'].dt.day\n",
    "\n",
    "train_all['order_pay_month'] = train_last['order_pay_time'].dt.month\n",
    "train_all['order_pay_dayofweek'] = train_last['order_pay_time'].dt.dayofweek\n",
    "train_all['order_pay_day'] = train_last['order_pay_time'].dt.day"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Feature Engineering "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 10.5 s, sys: 1.79 s, total: 12.3 s\n",
      "Wall time: 12.3 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "for idx,data in enumerate([train_last,train_all]):\n",
    "    customer_all = pd.DataFrame(data[['customer_id']]).drop_duplicates(['customer_id']).dropna()\n",
    "    data = data.sort_values(by=['customer_id','order_pay_time'])\n",
    "\n",
    "    data['count'] = 1\n",
    "    tmp = data.groupby(['customer_id'])['count'].agg({'customer_counts':'count'}).reset_index()\n",
    "    customer_all = customer_all.merge(tmp,on=['customer_id'],how='left')\n",
    "\n",
    "    tmp = data.groupby(['customer_id'])['customer_province'].last().reset_index()\n",
    "    customer_all = customer_all.merge(tmp,on=['customer_id'],how='left')\n",
    "\n",
    "    tmp = data.groupby(['customer_id'])['customer_city'].last().reset_index()\n",
    "    customer_all = customer_all.merge(tmp,on=['customer_id'],how='left')\n",
    "\n",
    "    tmp = data.groupby(['customer_id'])['member_status'].last().reset_index()\n",
    "    customer_all = customer_all.merge(tmp,on=['customer_id'],how='left')\n",
    "\n",
    "    tmp = data.groupby(['customer_id'])['is_member_actived'].last().reset_index()\n",
    "    customer_all = customer_all.merge(tmp,on=['customer_id'],how='left')\n",
    "    \n",
    "    data['count'] = 1\n",
    "    tmp = data[data['is_customer_rate']==0].groupby(['customer_id'])['count'].agg({'is_customer_rate_0':'count'}).reset_index()\n",
    "    customer_all = customer_all.merge(tmp,on=['customer_id'],how='left')\n",
    "\n",
    "    data['count'] = 1\n",
    "    tmp = data[data['is_customer_rate']==1].groupby(['customer_id'])['count'].agg({'is_customer_rate_1':'count'}).reset_index()\n",
    "    customer_all = customer_all.merge(tmp,on=['customer_id'],how='left')  \n",
    "    \n",
    "    data['count'] = 1\n",
    "    tmp = data[(data['is_member_actived']==1) & (data['goods_has_discount']==1)].groupby(['customer_id'])['count'].agg({'is_customer_have_discount_count':'count'}).reset_index()\n",
    "    customer_all = customer_all.merge(tmp,on=['customer_id'],how='left')\n",
    "    \n",
    "    if idx == 0:\n",
    "        last_data = last_data.merge(customer_all, on='customer_id', how='left')\n",
    "    else:\n",
    "        all_data = all_data.merge(customer_all, on='customer_id', how='left')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 5.22 s, sys: 768 ms, total: 5.99 s\n",
      "Wall time: 5.99 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "for idx,data in enumerate([train_last,train_all]):\n",
    "    customer_all = pd.DataFrame(data[['customer_id']]).drop_duplicates(['customer_id']).dropna()\n",
    "\n",
    "    tmp = data.groupby(['customer_id'],as_index=False)['goods_price'].agg({'goods_price_max':'max','goods_price_min':'min','goods_price_mean':'mean'})\n",
    "    customer_all = customer_all.merge(tmp,on=['customer_id'],how='left')\n",
    "\n",
    "    data['count'] = 1\n",
    "    tmp = data[data['goods_has_discount']==1].groupby(['customer_id'])['count'].agg({'goods_has_discount_counts':'count'}).reset_index()\n",
    "    customer_all = customer_all.merge(tmp,on=['customer_id'],how='left')\n",
    "\n",
    "    data['count'] = 1\n",
    "    tmp = data[data['goods_has_discount']==0].groupby(['customer_id'])['count'].agg({'goods_has_not_discount_counts':'count'}).reset_index()\n",
    "    customer_all = customer_all.merge(tmp,on=['customer_id'],how='left')\n",
    "\n",
    "    data['count'] = 1\n",
    "    tmp = data[data['goods_status']==1].groupby(['customer_id'])['count'].agg({'goods_status_1':'count'}).reset_index()\n",
    "    customer_all = customer_all.merge(tmp,on=['customer_id'],how='left')\n",
    "\n",
    "  \n",
    "    \n",
    "    if idx == 0:\n",
    "        last_data = last_data.merge(customer_all, on='customer_id', how='left')\n",
    "    else:\n",
    "        all_data = all_data.merge(customer_all, on='customer_id', how='left')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 7.11 s, sys: 536 ms, total: 7.65 s\n",
      "Wall time: 8.87 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "for idx,data in enumerate([train_last,train_all]):\n",
    "    customer_all = pd.DataFrame(data[['customer_id']]).drop_duplicates(['customer_id']).dropna()\n",
    "\n",
    "    tmp = data.groupby(['customer_id'])['order_amount'].agg({'order_amount_sum':'sum'})\n",
    "    customer_all = customer_all.merge(tmp,on=['customer_id'],how='left')    \n",
    "    \n",
    "    tmp = data.groupby(['customer_id'])['order_total_payment'].agg({'order_total_payment_sum':'sum','order_total_payment_count':'count'})\n",
    "    customer_all = customer_all.merge(tmp,on=['customer_id'],how='left')\n",
    "\n",
    "    tmp = data.groupby(['customer_id'])['order_total_discount'].agg({'order_total_discount_sum':'sum'})\n",
    "    customer_all = customer_all.merge(tmp,on=['customer_id'],how='left') \n",
    "\n",
    "    tmp = data.groupby(['customer_id'])['order_status'].agg({'order_status_max':'max'})\n",
    "    customer_all = customer_all.merge(tmp,on=['customer_id'],how='left')   \n",
    "    \n",
    "    data['count'] = 1\n",
    "    tmp = data[data['goods_status']==2].groupby(['customer_id'])['count'].agg({'goods_status_2':'count'}).reset_index()\n",
    "    customer_all = customer_all.merge(tmp,on=['customer_id'],how='left') \n",
    "    \n",
    "     \n",
    "\n",
    "    if idx == 0:\n",
    "        last_data = last_data.merge(customer_all, on='customer_id', how='left')\n",
    "    else:\n",
    "        all_data = all_data.merge(customer_all, on='customer_id', how='left')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 6 s, sys: 216 ms, total: 6.22 s\n",
      "Wall time: 6.21 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "for idx,data in enumerate([train_last,train_all]):\n",
    "    customer_all = pd.DataFrame(data[['customer_id']]).drop_duplicates(['customer_id']).dropna()\n",
    "\n",
    "    tmp = data.groupby(['customer_id'])['order_detail_amount'].agg({'order_detail_amount_sum':'sum'})\n",
    "    customer_all = customer_all.merge(tmp,on=['customer_id'],how='left')     \n",
    "    \n",
    "    tmp = data.groupby(['customer_id'])['order_detail_payment'].agg({'order_detail_payment_sum':'sum','order_detail_payment_count':'count'})\n",
    "    customer_all = customer_all.merge(tmp,on=['customer_id'],how='left')\n",
    "\n",
    "    tmp = data.groupby(['customer_id'])['order_detail_discount'].agg({'order_detail_discount_sum':'sum'})\n",
    "    customer_all = customer_all.merge(tmp,on=['customer_id'],how='left') \n",
    "\n",
    "    tmp = data.groupby(['customer_id'])['order_detail_status'].agg({'order_detail_status_max':'max'})\n",
    "    customer_all = customer_all.merge(tmp,on=['customer_id'],how='left')   \n",
    "    \n",
    "    \n",
    "    if idx == 0:\n",
    "        last_data = last_data.merge(customer_all, on='customer_id', how='left')\n",
    "    else:\n",
    "        all_data = all_data.merge(customer_all, on='customer_id', how='left')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 17min 53s, sys: 40 s, total: 18min 33s\n",
      "Wall time: 5min 22s\n"
     ]
    }
   ],
   "source": [
    "# %%time\n",
    "# for idx,data in enumerate([train_last,train_all]):\n",
    "#     customer_all = pd.DataFrame(data[['customer_id']]).drop_duplicates(['customer_id']).dropna()\n",
    "    \n",
    "#     tmp = data.groupby(['customer_id'])['goods_id'].apply(lambda x:','.join(x.astype(str))).reset_index()\n",
    "#     tmp.columns = ['customer_id','customer_goods_ids']\n",
    "#     customer_all = customer_all.merge(tmp, on='customer_id', how='left')\n",
    "    \n",
    "#     X_seller = TfidfVectorizer(token_pattern='[0-9]+',binary=True).fit_transform(customer_all['customer_goods_ids'].fillna('0'))\n",
    "#     seller_svd = TruncatedSVD(n_components=30,n_iter=30,random_state=2019).fit_transform(X_seller)\n",
    "#     seller_svd_df = pd.DataFrame(seller_svd, columns=['customer_goods_svd_{}'.format(i) for i in range(1,31)])\n",
    "#     customer_all = pd.concat([customer_all,seller_svd_df], axis=1)\n",
    "\n",
    "#     if idx == 0:\n",
    "#         last_data = last_data.merge(customer_all, on='customer_id', how='left')\n",
    "#     else:\n",
    "#         all_data = all_data.merge(customer_all, on='customer_id', how='left')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 2.75 s, sys: 352 ms, total: 3.1 s\n",
      "Wall time: 3.1 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "for idx,data in enumerate([train_last,train_all]):\n",
    "    customer_all = pd.DataFrame(data[['customer_id']]).drop_duplicates(['customer_id']).dropna()\n",
    "    data['order_pay_dayofyear'] = data['order_pay_time'].dt.dayofyear\n",
    "\n",
    "    tmp = data.groupby(['customer_id'])['order_pay_dayofyear'].agg({'order_pay_dayofyear_max':'max','order_pay_dayofyear_min':'min'})\n",
    "    customer_all = customer_all.merge(tmp,on=['customer_id'],how='left')   \n",
    "\n",
    "    if idx == 0:\n",
    "        last_data = last_data.merge(customer_all, on='customer_id', how='left')\n",
    "    else:\n",
    "        all_data = all_data.merge(customer_all, on='customer_id', how='left')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['order_detail_id', 'order_id', 'order_total_num', 'order_amount',\n",
       "       'order_total_payment', 'order_total_discount', 'order_pay_time',\n",
       "       'order_status', 'order_count', 'is_customer_rate',\n",
       "       'order_detail_status', 'order_detail_goods_num', 'order_detail_amount',\n",
       "       'order_detail_payment', 'order_detail_discount', 'customer_province',\n",
       "       'customer_city', 'member_id', 'customer_id', 'customer_gender',\n",
       "       'member_status', 'is_member_actived', 'goods_id', 'goods_price',\n",
       "       'goods_status', 'goods_has_discount', 'goods_list_time',\n",
       "       'goods_delist_time', 'order_pay_month', 'order_pay_dayofweek',\n",
       "       'order_pay_day', 'count'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_last.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "for data in [last_data, all_data]:\n",
    "    data['customer_city'] = LabelEncoder().fit_transform(data['customer_city'].fillna('None'))\n",
    "    data['customer_province'] = LabelEncoder().fit_transform(data['customer_province'].fillna('None'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_label(data,label):\n",
    "    data['label'] = 0\n",
    "    valid_idx_list = list(label['customer_id'].unique())\n",
    "    data['label'][data['customer_id'].isin(valid_idx_list)] = 1\n",
    "\n",
    "    return data\n",
    "\n",
    "last_data = generate_label(last_data,train_label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "last_data['order_pay_dayofyear_gap'] = last_data['order_pay_dayofyear_max'] - last_data['order_pay_dayofyear_min']\n",
    "all_data['order_pay_dayofyear_gap'] = all_data['order_pay_dayofyear_max'] - all_data['order_pay_dayofyear_min']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "last_data.drop(['order_pay_dayofyear_max','order_pay_dayofyear_min'], axis=1, inplace=True)\n",
    "all_data.drop(['order_pay_dayofyear_max','order_pay_dayofyear_min'], axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Feature Length: 28  Data prepared......\n"
     ]
    }
   ],
   "source": [
    "origin_feat = ['customer_counts','goods_price_max', 'goods_price_min', 'goods_price_mean','member_status','is_member_actived',\n",
    "               'customer_city','customer_province','goods_has_discount_counts','goods_has_not_discount_counts','goods_status_1',\n",
    "              'goods_status_2','is_customer_rate_0','is_customer_rate_1','is_customer_have_discount_count']\n",
    "\n",
    "main_order_feat = ['order_total_payment_sum','order_total_payment_count','order_total_discount_sum',\n",
    "                   'order_amount_sum','order_status_max','order_pay_dayofyear_max','order_pay_dayofyear_min',\n",
    "                   'order_pay_dayofyear_gap']\n",
    "                  \n",
    "                  \n",
    "\n",
    "detail_order_feat = ['order_detail_payment_sum','order_detail_payment_count','order_detail_discount_sum',\n",
    "                     'order_detail_amount_sum','order_detail_status_max']\n",
    "\n",
    "##########################################################################################\n",
    "feature = origin_feat + main_order_feat + detail_order_feat\n",
    "\n",
    "X = last_data[feature]\n",
    "y = last_data['label']\n",
    "X_all = all_data[feature]\n",
    "\n",
    "X_train, X_valid, y_train, y_valid = train_test_split(X, y, test_size=0.1, random_state=42,stratify=y)\n",
    "print('Feature Length:',len(feature),' Data prepared......')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training until validation scores don't improve for 100 rounds.\n",
      "[50]\tvalid_0's binary_logloss: 0.395892\n",
      "[100]\tvalid_0's binary_logloss: 0.39609\n",
      "[150]\tvalid_0's binary_logloss: 0.396465\n",
      "Early stopping, best iteration is:\n",
      "[64]\tvalid_0's binary_logloss: 0.395797\n"
     ]
    }
   ],
   "source": [
    "def re_logloss(labels,preds):   \n",
    "    deta = 3.4\n",
    "    y_true = labels   # you can try this eval metric for fun\n",
    "    y_pred = preds\n",
    "    p = np.clip(y_pred, 1e-10, 1-1e-10)\n",
    "    loss = -1/len(y_true) * np.sum(y_true * np.log(p) * deta + (1 - y_true) * np.log(1-p))\n",
    "    return 're_logloss',loss,False\n",
    "\n",
    "lgb_model = lgb.LGBMClassifier(boosting_type='gbdt', num_leaves=64, reg_alpha=0.1, reg_lambda=1.0,\n",
    "                                max_depth=-1, n_estimators=10000, objective='binary', metrics='None', \n",
    "                                bagging_fraction=0.8, is_unbalance=False, bagging_freq=5, min_child_samples=80, \n",
    "                                feature_fraction=0.8, learning_rate=0.1, random_state=42, n_jobs=8,\n",
    "                                )\n",
    "\n",
    "eval_set = [(X_valid, y_valid)]\n",
    "lgb_model.fit(X_train, y_train, eval_set=eval_set, eval_metric='logloss',verbose=50, early_stopping_rounds=100)\n",
    "pred = lgb_model.predict_proba(X_all) #0.3958"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "res = all_data[['customer_id']]\n",
    "res['result'] = pred[:,1]\n",
    "\n",
    "data = pd.DataFrame(train[['customer_id']]).drop_duplicates(['customer_id']).dropna()\n",
    "data = (data.merge(res,on=['customer_id'],how='left')).sort_values(['customer_id'])\n",
    "data['customer_id'] = data['customer_id'].astype('int64')\n",
    "data['result'] = data['result'].fillna(0)\n",
    "result = data[['customer_id','result']]\n",
    "result.to_csv('../out/round1_diac2019_test.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
